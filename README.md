# Python

A PyTorch implementation of universal attack. Refer to the original [*tensorflow code*](https://github.com/LTS4/universal). 
**But I find that when I use the same dataset(10,000), my code can only fool 30% images in Validation set(50,000). Looking forward to your help!**
## Usage

### Get started

To get started, you can run the following demo code
```
python search.py
```

## Reference
[1] S. Moosavi-Dezfooli\*, A. Fawzi\*, O. Fawzi, P. Frossard:
[*Universal adversarial perturbations*](http://arxiv.org/pdf/1610.08401), CVPR 2017

